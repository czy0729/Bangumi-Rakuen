{"id":379479,"avatar":"//lain.bgm.tv/pic/user/m/000/57/39/573903.jpg","floor":"#1","group":"靠谱人生茶话会","groupHref":"/group/boring","groupThumb":"//lain.bgm.tv/pic/icon/m/000/00/03/364.jpg","message":"目前的 ChatGPT 是有逻辑推理能力的, 但是被限制在一个聊天框里面, 所以有了这么个想法...<br><br>首先是 Google 前几天的 PaLM-E 模型, 结构和 GPT 类似, 但是多了图像和机械臂操作的旁路, 训练出的模型可以接受语言指令通过摄像头和机械臂在现实世界执行任务: <a href=\"https://palm-e.github.io/\" target=\"_blank\" rel=\"nofollow external noopener noreferrer\" class=\"l\">https://palm-e.github.io/</a><br><br>然后是 OpenAI 之前整的一些活, 在一个虚拟环境里 (有点类似 minecraft) 通过游戏训练模型, 让他们自发学会使用工具等技能, 比如这篇: <a href=\"https://openai.com/research/emergent-tool-use\" target=\"_blank\" rel=\"nofollow external noopener noreferrer\" class=\"l\">https://openai.com/research/emergent-tool-use</a><br><br>所以可以设想这么个实验: 把 GPT 加上视觉输入(GPT-4 已经有了) 和一些操作输出 (这个还没, 但是 GPT 本身差不多可以就通过语言输出做一些操作, 比如通过输出 ←↑→ 这些字符操作对应手柄按键), 把多个副本放进类似 minecraft 的一个仿真世界, 他们可以操作里面的角色, 并通过学会的人类语言进行沟通, 这个过程中不断筛选出来存活时间更长的副本.<br><br>感觉上类似初版的 AlphaGo, 先学习人类对局(人类逻辑/语言), 然后通过自我对局(在游戏里生存)优化参数. AlphaGo 进化成了超越人类的围棋 AI, 那么 ChatGPT 会变成什么样子呢 <img src=\"/img/smiles/tv/65.gif\" smileid=\"104\" alt=\"(bgm88)\"> ","time":"2023-3-24 11:08","title":"一个关于 ChatGPT 的想法","userId":"573903","userName":"A1chemist","userSign":""}