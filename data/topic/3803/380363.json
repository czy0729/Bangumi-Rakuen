{"id":380363,"avatar":"//lain.bgm.tv/pic/user/m/000/57/39/573903.jpg","floor":"#1","group":"～技术宅真可怕～","groupHref":"/group/a","groupThumb":"//lain.bgm.tv/pic/icon/m/000/00/00/11.jpg","message":"<a href=\"https://zhuanlan.zhihu.com/p/621608363\" target=\"_blank\" rel=\"nofollow external noopener noreferrer\" class=\"l\">https://zhuanlan.zhihu.com/p/621608363</a><br>一组 Python 脚本, 循环调用 ChatGPT 并提示它一步一步地解决问题, 看起来像是 ChatGPT 在不断思考.<br><a href=\"https://zhuanlan.zhihu.com/p/621046852\" target=\"_blank\" rel=\"nofollow external noopener noreferrer\" class=\"l\">https://zhuanlan.zhihu.com/p/621046852</a><br>让 ChatGPT 操作 25 个角色在一个类似星露谷的小镇上互动.<br><br>最近看到的两个项目, 虽然表面上看关联不大, 但是仔细看实现细节的话, 会发现都需要处理一个核心问题: ChatGPT 的记忆.<br><br>大家在聊天窗口和 ChatGPT 交互的时候, 会有这么种错觉: ChatGPT 在时间上是连续存在的, 它把聊天历史 \"记忆\" 在了自己的内存里面, 所以可以和用户不断交流. 但是实际上发生的事情更类似这样: OpenAI 手中有很多 ChatGPT 的个体 (GPU 里面存储的一些张量的集合), 用户在输入一个问题之后, 其中一个 ChatGPT 会被分配任务会生成对应的回答, 之后就会被重置自己的所有状态. 用户输入下一个问题时, 另一个 ChatGPT 被分配过来, 它会从头开始阅读这次聊天的所有历史, 给出回答之后同样被重置, 如此循环往复. 一个 ChatGPT 在完成回答之后如果因为断电之类的原因 \"死掉\", 也完全不会影响对话的连续性, 因为另一个个体会补上它的位置.<br><br>广义上看, 倒也可以认为聊天历史就是 ChatGPT 的 \"记忆\", 它负责思考和记忆的 \"器官\" 是分开的, 不像人类都是用大脑. 前面两个项目也是按照这个思路设计, 他们都会在自己的本地脚本里面存储下和 ChatGPT 的交互历史, 然后不断地把这个历史给 ChatGPT, 并让它思考下一步要做什么.<br><br>这种方式不算太合理, 因为这些历史是用自然语言编码的, 信息量比 ChatGPT 的内部编码低, 而且会有编解码过程的信息损失. 感觉上是在没办法改动 ChatGPT 模型本体这一限制下的某种妥协. 如果未来 OpenAI 直接从模型结构上做改进, 让模型可以直接在一些张量里面存储自己的记忆, 说不定能让 ChatGPT 变得更聪明全能一些? ","time":"2023-4-13 17:21","title":"ChatGPT 有记忆吗?","userId":"573903","userName":"A1chemist","userSign":""}