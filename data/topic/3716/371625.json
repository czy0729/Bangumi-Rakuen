{"id":371625,"avatar":"//lain.bgm.tv/pic/user/m/000/06/34/63429.jpg","floor":"#1","group":"靠谱人生茶话会","groupHref":"/group/boring","groupThumb":"//lain.bgm.tv/pic/icon/m/000/00/03/364.jpg","message":"据我对这两年人工智能技术发展的粗浅了解，目前为止研究人员也不是特别清楚现在的算法(主要指的是深度学习这块)是自己怎么进化怎么思考的，它们对人类来说某种程度上算是个研究领域上的“黑箱”了。<br>但是我觉得既然现在这种弱人工智能都已经让人类无法完全掌握AI的全部运行细节，那么将来真的实现了强人工智能的话，人类更不可能会理解AI会“想什么”。<br>但是有个很有趣的现象，之前的各类科幻作品里，对于这种人类无法掌握的有自主意识的人工智能，它们往往将其描述为“AI觉醒后觉得人类这种生物存在是没有价值的，应该要消灭掉”所以发展方向又是人类和AI拼个你死我活的死斗故事(而且人类方往往还是输家)<br>我就纳闷了，既然我们都无法理解AI将来会怎么思考，为啥就一定会天然认为它们一定要反过来消灭人类呢？是我们的忧患意识让这类科幻创作都不约而同这么搞了吗？<br>亦或是说科幻创作者其实因为不懂或者装不懂，所以故意这么设置来搞矛盾冲突而已? ","time":"2022-7-16 20:48","title":"既然人类都不理解人工智能“想什么”，那为何在科幻作品里往往设定成它们要消灭人类呢？","userId":"akb49","userName":"老白","userSign":"(Anime is trash and so am I.)"}