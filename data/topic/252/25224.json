{"id":25224,"avatar":"//lain.bgm.tv/pic/user/m/000/06/21/62186.jpg","floor":"#1","group":"～技术宅真可怕～","groupHref":"/group/a","groupThumb":"//lain.bgm.tv/pic/icon/m/000/00/00/11.jpg","message":"如题, 希望得到一个类似\"<br>[[词条名]]<br>内容..<br>..内容<br>[[下一条词条名]]<br>..<br>\"的纯文本<br>从mediawiki可以下载到一个xml的dump文件. 可以用wp2txt或者wikiextractor提取出纯文本. 但是这个dumps文件里的内容用到了不少模板,比如{{bd|1912年||2000年|}}输出结果应该为1912年－2000年, 用上面两个软件是无法解析模板的.<br>所以觉得应该把dump文件导入本地mediawiki, 然后本地用什么软件把mediawiki解析出的模板的html页面分析保存在一个文本文件里.<br>用mwdumper把xml转成sql导入时, mysql不支持unicode扩展汉字...(wamp, mysql 5.5), mediawiki改为二进制存储就可以了. 导入完成后, 再用什么才能抓下所有内容...还是只能自己写脚本?<br>或者有没有能直接读xml并且解析模板然后输出的东西? ","time":"2013-8-7 16:50","title":"怎么把所有维基百科词条变成一个纯文本","userId":"epix","userName":"epix","userSign":"((((；ﾟДﾟ)))))))"}