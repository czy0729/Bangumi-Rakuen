{"id":416268,"avatar":"//lain.bgm.tv/pic/user/m/000/71/46/714685.jpg","floor":"#1","group":"～技术宅真可怕～","groupHref":"/group/a","groupThumb":"//lain.bgm.tv/pic/icon/m/000/00/00/11.jpg","message":"线上的大模型虽然更强大，但大多都是有河蟹机制的，不能ghs，当然也有一些破限技巧，具体没研究过。于是我最近开始尝试在电脑本地部署一些小参数的uncensored模型，尝试用来写刘备。我是用游戏本部署的，硬件配置是R7 5800H + RTX 3060 6G + 32G内存，主要是显存太小。<br><br>下面简单说一下目前尝试过的模型：<br>deepseek-r1-7b的各种uncensored版本：尝试过好几个版本都完全不行，14b或32b的没试过。<br>Qwen-2.5-7B-Instruct-novel-lora：专门针对ghs进行微调的模型。写得确实够涩，但智商一般，逻辑有点不清，而且不知道是不是我配置参数有问题，它会写个不停，完全停不下来。如果就喜欢纯无脑看涩涩的可以用这个。<br>mistral-nemo：原生支持NSFW（但也偶尔会拒绝写），整体还不错，但有时写着写着就变成英文了（可以通过prompt强制中文），并且有时会发癫。<br>saiga-nemo：基于mistral-nemo微调的模型。它是针对俄语进行微调的，但神奇的是中文能力也进步了，目前用过的最好的。<br><br>当然，毕竟我显存不够大，saiga-nemo（以及上面的mistral-nemo）都是12b的模型，运行的时候会额外占用几G内存用CPU跑，所以写得很慢，还是比较影响体验的。<br><br>接下来，我可能会试试租云服务器玩，这样能够有更好的体验，也能尝试别的对显存要求更高的模型。","time":"2025-2-11 09:58","title":"尝试在电脑本地部署语言模型写刘备文","userId":"714685","userName":"h3nt4i","userSign":""}