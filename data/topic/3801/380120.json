{"id":380120,"avatar":"//lain.bgm.tv/pic/user/m/000/35/13/351390.jpg","floor":"#1","group":"ï½æŠ€æœ¯å®…çœŸå¯æ€•ï½","groupHref":"/group/a","groupThumb":"//lain.bgm.tv/pic/icon/m/000/00/00/11.jpg","message":"å½“å‰ç¯å¢ƒä¸‹ï¼ŒGPT-4å·²ç»æœ‰äº†å¾ˆå¼ºçš„å†™ä»£ç /ç¼–ç¨‹çš„èƒ½åŠ›ã€‚è¿™ç§èƒ½åŠ›ä¸æ˜¯ç®€å•ç¬¨æ‹™çš„æ¨¡ä»¿ï¼Œè€Œæ˜¯åœ¨ç†è§£äº†ç¼–ç¨‹è¯­ä¹‰çš„åŸºç¡€ä¸Šè¿›è¡Œå¼€å‘çš„ã€‚<br><br>å…³äºGPT-4çš„æŠ€æœ¯ç»†èŠ‚å¾ˆå¤æ‚ï¼Œæˆ‘è‡ªå·±ä¹Ÿæ²¡æœ‰æå¾—æ‡‚ï¼Œä½†æ˜¯æˆ‘å¯ä»¥ä»DeepMindå…¬å¸çš„AlphaGoä¸AlphaGo Zeroçš„å‘å±•ä¸­çª¥æ¢AIçš„è¿­ä»£ä¹‹è·¯ã€‚<br><br>ä¸ºä»€ä¹ˆè¯´ï¼ŒAIæ‹¥æœ‰è‡ªæˆ‘è¿­ä»£çš„èƒ½åŠ›å‘¢ï¼Ÿ<br>å¼•ç”¨è®ºæ–‡ï¼š<a href=\"https://sci-hub.se/10.1145/3206157.3206174\" target=\"_blank\" rel=\"nofollow external noopener noreferrer\" class=\"l\">Holcomb S D, Porter W K, Ault S V, et al. Overview on deepmind and its alphago zero ai[C]//Proceedings of the 2018 international conference on big data and education. 2018: 67-71.</a><br><br>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<br><br>åœ¨è¿™ç¯‡è®ºæ–‡é‡Œè®²è¿°äº†AlphaGoä¸AlphaGo ZEROçš„åŒºåˆ«<br><br>å¯¹äºAlphaGOï¼Œå…¶æœ¬è´¨çš„ç‰¹è‰²åœ¨äºå­¦ä¹ ï¼Œå®ƒæ˜¯ä¸€ç§ä»¥å­¦ä¹ ä¸ºå¯¼å‘æ„ç­‘çš„å›´æ£‹æ¨¡å‹ã€‚<br>åœ¨å­¦ä¹ äº†åƒä¸‡çº§åˆ«çš„äººç±»çš„æ£‹è°±ä¹‹åï¼ŒAlphaGoåœ¨ä¸‹æ£‹çš„è¿‡ç¨‹ä¸­å¯ä»¥æ¨¡ä»¿äººç±»çš„æŠ€å·§è¿›è¡Œå¯¹å¼ˆã€‚<br><br>è€ŒAlphaGo Zeroå´æœ‰å¾ˆå¤§ä¸åŒï¼ŒAlphaGo Zeroçš„æå‡åœ¨äºè‡ªæˆ‘åšå¼ˆï¼Œè‡ªä¸»æŠ€èƒ½è¿­ä»£ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºAlphaGo Zeroå®ƒä¸éœ€è¦äººç±»ä½œä¸ºå¯¼å¸ˆï¼Œä¹Ÿä¸éœ€è¦å­¦ä¹ å¤§é‡çš„äººç±»æ£‹ç›˜ï¼Œå®ƒå¯ä»¥é€šè¿‡è‡ªæˆ‘åšå¼ˆä¼˜åŒ–ç®—æ³•ï¼Œæœ€åæå‡æ£‹ç±»å®åŠ›ã€‚<br><br>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<div class=\"quote\"><q>The largest changes from AlphaGo and AlphaGo Zero are self\u0002play, use of only black and white stones on the board as input, and use a single artificial neural network for both value and policy. Zero, while able to be used in a distributed manner, \"uses just a single machine in the Google Cloud with 4 TPUsâ€ for the sake of simplicity. It is a small list of changes, but each item contained involved complex work that needed to be done.<br>AlphaGo was fed large quantities of human-played games to learn the game whereas Zero learned purely through reinforcement playing itself. The entails the ability to learn with as little human guidance as possible and a larger step towards a more generalized AI ability. Reliance on human data can also be a limiting factor since large and complete datasets are not always readily available. Additionally, with the aim of learning from AI as well as the AI learning from us, allowing the freedom of unguided learning can provide alternate and unpredictable patterns to be discovered where human data could have interfered. Use of only black and white stones as input also provides a more generalized vantage by being closer to the input a human takes in when playing the game.</q></div>ç¿»è¯‘ï¼š<br>AlphaGoå’ŒAlphaGo Zeroæœ€å¤§çš„å˜åŒ–åœ¨äºè‡ªæˆ‘åšå¼ˆã€ä»…ä½¿ç”¨é»‘ç™½æ£‹å­ä½œä¸ºè¾“å…¥ä»¥åŠä½¿ç”¨å•ä¸ªäººå·¥ç¥ç»ç½‘ç»œæ¥å¤„ç†ä»·å€¼å’Œç­–ç•¥ã€‚Zeroå¯ä»¥åˆ†å¸ƒå¼ä½¿ç”¨ï¼Œä½†å‡ºäºç®€å•èµ·è§ï¼Œâ€œä»…ä½¿ç”¨è°·æ­Œäº‘ä¸­å¸¦æœ‰4ä¸ªTPUçš„å•ä¸ªè®¡ç®—æœºâ€ã€‚è™½ç„¶å˜åŒ–åˆ—è¡¨å¾ˆçŸ­ï¼Œä½†æ¯ä¸ªæ¡ç›®éƒ½æ¶‰åŠéœ€è¦å®Œæˆçš„å¤æ‚å·¥ä½œã€‚<br>AlphaGoé€šè¿‡å­¦ä¹ äººç±»ç©è¿‡çš„å¤§é‡æ¸¸æˆæ¥å­¦ä¹ æ¸¸æˆï¼Œè€ŒZeroåˆ™æ˜¯é€šè¿‡è‡ªæˆ‘å¼ºåŒ–å­¦ä¹ çº¯ç²¹åœ°å­¦ä¹ ã€‚è¿™æ„å‘³ç€èƒ½å¤Ÿå°½å¯èƒ½å°‘åœ°ä¾èµ–äººç±»æŒ‡å¯¼ï¼Œå¹¶æ›´å¤§ç¨‹åº¦åœ°å®ç°é€šç”¨äººå·¥æ™ºèƒ½çš„ç›®æ ‡ã€‚ä¾èµ–äººç±»æ•°æ®ä¹Ÿå¯èƒ½æˆä¸ºé™åˆ¶å› ç´ ï¼Œå› ä¸ºå¤§è€Œå…¨çš„æ•°æ®é›†å¹¶ä¸æ€»æ˜¯å®¹æ˜“è·å¾—ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä»AIä¸­å­¦ä¹ ï¼ŒåŒæ—¶è®©AIä»æˆ‘ä»¬ä¸­å­¦ä¹ ï¼Œå…è®¸è‡ªç”±çš„æ— æŒ‡å¯¼å­¦ä¹ å¯ä»¥å‘ç°ä¸äººç±»æ•°æ®å¹²æ‰°ä¸åŒçš„æ›¿ä»£å’Œä¸å¯é¢„æµ‹çš„æ¨¡å¼ã€‚ä»…ä½¿ç”¨é»‘ç™½æ£‹å­ä½œä¸ºè¾“å…¥è¿˜æä¾›äº†æ›´æ¥è¿‘äººç±»ä¸‹æ£‹æ—¶æ‰€é‡‡å–çš„è§†è§’ï¼Œä»è€Œæä¾›äº†ä¸€ç§æ›´é€šç”¨çš„è§†è§’ã€‚<br><br>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<div class=\"quote\"><q>With the goal of improving an AI that can already defeat Go champions, even a marginal gain would be a significant accomplishment. AlphaGo Zero did more than a marginal gain. In a match against the previous version that defeated the Lee Sedol, AlphaGo Zero defeated its predecessor 100 â€“ 0. A solid win shows a clear increase in performance. </q></div>ç¿»è¯‘ï¼š<br>ä»¥æé«˜å·²ç»èƒ½å¤Ÿå‡»è´¥å›´æ£‹å† å†›çš„äººå·¥æ™ºèƒ½ä¸ºç›®æ ‡ï¼Œå³ä½¿æ˜¯å¾®å°çš„å¢ç›Šä¹Ÿæ˜¯ä¸€ä¸ªé‡å¤§çš„æˆå°±ã€‚AlphaGo Zeroä¸ä»…å–å¾—äº†å¾®å°çš„å¢ç›Šã€‚åœ¨ä¸å‡»è´¥æä¸–çŸ³çš„å…ˆå‰ç‰ˆæœ¬å¯¹å†³ä¸­ï¼Œ<span style=\"font-weight:bold;\">AlphaGo Zeroä»¥100æ¯”0å‡»è´¥äº†å…¶å‰è¾ˆ</span>ã€‚åšå®çš„èƒœåˆ©æ˜¾ç¤ºå‡ºæ˜æ˜¾çš„æ€§èƒ½æå‡ã€‚<br><br>è‡ªæˆ‘è¿­ä»£æ¨¡å‹AlphaGo Zeroç›¸æ¯”äºå­¦ä¹ æ¨¡å‹AlphaGo Leeæ‹¥æœ‰ç¢¾å‹æ€§çš„ä¼˜åŠ¿ï¼Œè¿™ç§ä¼˜åŠ¿ä¸å…‰ä½“ç°åœ¨ç»“æœä¸Šï¼Œä¹Ÿä½“ç°åœ¨è®­ç»ƒæ—¶é—´ä¸Šï¼ŒAlphaGo Zeroç”¨è¿œå°‘äºå­¦ä¹ å‹æ¨¡å‹çš„æ—¶é—´ä¸ç®—åŠ›è·å¾—äº†æ›´å¥½æ›´å¼ºçš„ç»“æœï¼<br><br>AIçš„æ¨¡å‹æœ€å¼€å§‹ä¹Ÿæ˜¯ä¾èµ–ç¼–ç¨‹è€Œè·å¾—çš„æ¶æ„ï¼ŒAIæœ‰äº†è‡ªæˆ‘åšå¼ˆçš„æ–¹å‘ï¼ŒAIæœ‰äº†ç¼–ç¨‹çš„èƒ½åŠ›ã€‚<br><br>é‚£ä¹ˆï¼ŒAIé€šè¿‡ç¼–å†™ä»£ç ï¼Œæ‹¥æœ‰è‡ªæˆ‘è¿›åŒ–ï¼Œæ‹¥æœ‰è‡ªæˆ‘è¿­ä»£èƒ½åŠ›çš„æœªæ¥è¿˜ä¼šè¿œå—ï¼Ÿ<br><br>å¤‡æ³¨ï¼š<br>AIå†™ä»£ç ï¼šMastropaolo A, Pascarella L, Guglielmi E, et al. On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot[J]. arXiv preprint arXiv:2302.00438, 2023.<br><br>AlphaGo Zeroä¸GPTçš„åŸºç¡€æ¨¡å‹ç›¸å·®ç”šè¿œï¼Œä½†éƒ½è¿ç”¨äº†transformeræŠ€æœ¯ã€‚ ","time":"2023-4-7 13:53","title":"AIçš„è‡ªæˆ‘è¿­ä»£ä¸åˆ›æ–°","userId":"lostpig","userName":"ğ™‡ğ™¤ğ™¨ğ™© ğ™‹ğ™ğ™œ ğŸ‰","userSign":"(è¢«é—å¿˜çš„å°çŒªä¼šè¢«é—å¿˜å—ï¼Ÿ)"}