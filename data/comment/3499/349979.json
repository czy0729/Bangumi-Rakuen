[{"avatar":"//lain.bgm.tv/pic/user/m/000/10/04/100498.jpg","floor":"#2","id":"1430869","time":"2019-3-27 21:52","userId":"bingshoulian","userName":"冰狩怜","userSign":"(精灵如果仰望星星,会变成星光;人类如果仰望星星,会创 ...)","message":"gal福音？可以自己做黄油了<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\"><br><span style=\"text-decoration: line-through;\">我记得之前好像也有类似的诶</span>","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#2-1","id":"1430877","time":"2019-3-27 22:08","userId":"197870","userName":"尤鱼哥","userSign":"","message":"说明一下，以前的大多是线稿自动上色，或者给定标签生成头像。但是要真的从随便画几笔的线条，涂几笔的颜色，就能生成细致的纹理，可能以前的方法都不太合适。超稀疏信息图像重建领域还在起步。具体可以看论文里的related works~"},{"avatar":"//lain.bgm.tv/pic/user/m/000/10/04/100498.jpg","floor":"#2-2","id":"1430959","time":"2019-3-28 10:32","userId":"bingshoulian","userName":"冰狩怜","userSign":"","message":"<div class=\"quote\"><q><span style=\"font-weight:bold;\">尤鱼哥</span> 说: 说明一下，以前的大多是线稿自动上色，或者给定标签生成头像。但是要真的从随便画几笔的线条，涂几笔的颜色，就能生成细致的纹理，可能以前的方法都不太合适。超稀疏信息图像重建领域还在起步。具体可以看论文里的r...</q></div>挺好奇这样版权算是谁的，自己的吗？"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/31/34/313469.jpg","floor":"#3","id":"1430873","time":"2019-3-27 22:02","userId":"313469","userName":"Cedar","userSign":"(｡´-д-)","message":"哇 你是作者之一嘛","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#3-1","id":"1430878","time":"2019-3-27 22:11","userId":"197870","userName":"尤鱼哥","userSign":"","message":"我是一作，前排说一下：AI图像翻译前沿领域，在顶会上基本是被UC伯克利和英伟达统领的。非常希望能看到，并推动国内大学在此领域获得更大突破~ 如果能激发各位的兴趣，想从事相关研究，那就达到我的目的啦~"},{"avatar":"//lain.bgm.tv/pic/user/m/000/20/67/206779.jpg","floor":"#3-2","id":"1431825","time":"2019-3-31 21:17","userId":"zq0504032","userName":"满舰饰假子","userSign":"","message":"<div class=\"quote\"><q><span style=\"font-weight:bold;\">尤鱼哥</span> 说: 我是一作，前排说一下：AI图像翻译前沿领域，在顶会上基本是被UC伯克利和英伟达统领的。非常希望能看到，并推动国内大学在此领域获得更大突破~ 如果能激发各位的兴趣，想从事相关研究，那就达到我的目的啦~</q></div>有不有这样一个软件好直接下载的?<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\">饭来伸手。。。<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\">"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/43/26/432689.jpg","floor":"#4","id":"1430890","time":"2019-3-27 22:41","userId":"kcrescent","userName":"Kcrescent","userSign":"","message":"<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\">对于画画来说，找准形也是很重要的啊，能画出五官的标准位置就已经不是绘画经验少的0基础者能做到的了","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/26/84/268422.jpg","floor":"#5","id":"1430899","time":"2019-3-27 23:06","userId":"alexio_yorbmapr","userName":"海盗丸子","userSign":"(影山浩宣唱OP，高桥洋子唱ED，这是毕生梦想，也是永远的梦想 ...)","message":"诶……我觉得他们还是先从线稿开始入手吧，有些地方还是错的离谱，一上来就要求上色绘图显然还是难度太高。","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/10/48/104848.jpg","floor":"#6","id":"1430914","time":"2019-3-27 23:48","userId":"batman","userName":"Nightwing","userSign":"(‮)","message":"mark","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/37/87/378785.jpg","floor":"#7","id":"1430920","time":"2019-3-28 00:37","userId":"willian","userName":"Willian","userSign":"","message":"realtime 演示太酷了、 求一個 iOS demo App","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/04/97/49777.jpg","floor":"#8","id":"1430932","time":"2019-3-28 01:16","userId":"bgmouse","userName":"MousHu","userSign":"(miaow~~~)","message":"标题党还好啦 hhh 现在看到这种标题基本也就能知道个大概了 ~ hhh<br>尤其是之前先看过老黄家他们的一些新演示之后吧 ... <br>更主要的是 前几年拖条勾选交互用的也是类似的标题 hhh <br>有宽松度上的突破 推广用的标题多想想会更好嘛 hhh<br>比如之前是手残党福音 ... 现在这明显拯救的就不是手残党了 ~ <br>怕不是 ~ 更有梦想的手残党了 hhh<br>这样的 ~ <img src=\"/img/smiles/tv/24.gif\" smileid=\"63\" alt=\"(bgm47)\"><br><br>向这个方向上的提升 ... 自己首先想到更贴近消费应用的还是服饰家具定制呀之类的 ... <br>更娱乐化一点想到的可能是 一些特效相机能有更好玩的 更具交互性玩具了什么的 ~<br><br>其它的一些减轻大批量“各类”“设计”压力等等的应用 也一直在这个方向上有受益 ... <br>也不只是画呀景呀头像呀什么 ... <br>有你们在前面 开拓呀 优化呀 或者说 分兴趣点分享示例呀 挺好的 ~ <img src=\"/img/smiles/tv/58.gif\" smileid=\"97\" alt=\"(bgm81)\"><br><br>像去年CVPR的另一方面的某篇 ... 自己这边 看着 ... <br>先是眼前一亮 感觉的确是给出了很有趣的希望 ...<br>（在整体效果方面 强的 ... 某几个我关注的具体方面效果真的好 ... 无论怎么看都相当爽 ...）<br>但之后 距离之前没这篇时的期望呢 觉得可能还是需要GAN向这边 也可能是应用结合向 ... <br>可能更多（共同与分别）的努力 ...<br>（其它有些方面 难搞的点即便在他们的范畴内还是头疼 ...... <br>有的看起来按这个方法或思路再多堆些量什么的可能还有点希望 ...<br>有的看起来也不是堆量或者小碎步优化能解决的 头疼呀头疼 hhh）<br><br>只能说 ... 共勉吧 ... <img src=\"/img/smiles/tv/49.gif\" smileid=\"88\" alt=\"(bgm72)\">","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#8-1","id":"1430947","time":"2019-3-28 09:41","userId":"197870","userName":"尤鱼哥","userSign":"","message":"共勉。无论是之前大炒的自动上色，图像翻译，手绘转真图，还是一些高清图像生成，超分辨率等等，目前看来离最终形态的AI自动绘画还是有一段距离的，我估计七八年左右英伟达可能可以第一个搞出来雏形。国内大多觉得没有商用价值不会特意去研究（感谢导师支持我）。<br>不过这论文里的两个输入：稀疏的边缘决定content，和大范围色块决定style，可能是最接近理想中的AI全自动绘画的输入了。输入再简陋就条件信息太少了，输入再丰富一般人也不好画……"},{"avatar":"//lain.bgm.tv/pic/user/m/000/04/97/49777.jpg","floor":"#8-2","id":"1430977","time":"2019-3-28 12:50","userId":"bgmouse","userName":"MousHu","userSign":"","message":"<div class=\"quote\"><q><span style=\"font-weight:bold;\">尤鱼哥</span> 说: 共勉。无论是之前大炒的自动上色，图像翻译，手绘转真图，还是一些高清图像生成，超分辨率等等，目前看来离最终形态的AI自动绘画还是有一段距离的，我估计七八年左右英伟达可能可以第一个搞出来雏形。国内大多觉得...</q></div>我反正感觉很难去想七八年这样的尺度 ... <br>指不定三四年就卡壳退热了 ...<br>指不定两三年又有些什么其它有趣的希望出来了 ...... <br>感觉都难说 ... 只能说一步步做 一步步看吧 ~"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/00/38/3811.jpg","floor":"#9","id":"1430937","time":"2019-3-28 03:52","userId":"kane","userName":"Kane","userSign":"(この勝利を、近所のおばさんに捧げる！ ... ... ... ... ...)","message":"咦不是GAN？","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#9-1","id":"1430944","time":"2019-3-28 09:32","userId":"197870","userName":"尤鱼哥","userSign":"","message":"当然用到啦~"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/42/01/420149.jpg","floor":"#10","id":"1430958","time":"2019-3-28 10:25","userId":"cocolate","userName":"CoColate","userSign":"(不存在的)","message":"哇这个真有点产业方向的实用性了<br>只要构图，粗略上个色调，就能自动细化成作品<br>省了99%的时间，是业界福音！","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/30/23/302323.jpg","floor":"#11","id":"1430960","time":"2019-3-28 10:46","userId":"brickmaycry","userName":"他人即地狱","userSign":"(无知即力量)","message":"Mark","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/21/04/210454.jpg","floor":"#12","id":"1430965","time":"2019-3-28 11:30","userId":"mp4spig","userName":"🌸九重凛🌸","userSign":"(人不抽我，我不抽人。人若抽我，我必抽人。 ...)","message":"这样画出来是没有灵魂的<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\">","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/09/06/90690.jpg","floor":"#12-1","id":"1430966","time":"2019-3-28 11:40","userId":"wattlebird","userName":"Genius、小乖🌟💯","userSign":"","message":"更准确地说，只是借用了别人的灵魂，然后装作是自己的。"},{"avatar":"//lain.bgm.tv/pic/user/m/000/02/31/23120.jpg","floor":"#12-2","id":"1430967","time":"2019-3-28 11:45","userId":"athrun1120","userName":"A.one","userSign":"","message":"<div class=\"quote\"><q><span style=\"font-weight:bold;\">Genius、小乖</span> 说: 更准确地说，只是借用了别人的灵魂，然后装作是自己的。</q></div>如果是从素材库里找匹配然后拼出来的 不会侵权么<img src=\"/img/smiles/tv/16.gif\" smileid=\"55\" alt=\"(bgm39)\"> 当然做个头像不产生商业利益是没问题"},{"avatar":"//lain.bgm.tv/pic/user/m/000/09/06/90690.jpg","floor":"#12-3","id":"1430972","time":"2019-3-28 12:11","userId":"wattlebird","userName":"Genius、小乖🌟💯","userSign":"","message":"<div class=\"quote\"><q><span style=\"font-weight:bold;\">A.one</span> 说: 如果是从素材库里找匹配然后拼出来的 不会侵权么 当然做个头像不产生商业利益是没问题</q></div>当然会。训练数据必须合规。"},{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#12-4","id":"1431140","time":"2019-3-29 10:22","userId":"197870","userName":"尤鱼哥","userSign":"","message":"良好的训练数据集，还有版权是非常重要的。这也是我们没有开放动漫头像数据集下载的原因（虽然有别人开了）"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/02/31/23120.jpg","floor":"#13","id":"1430970","time":"2019-3-28 12:03","userId":"athrun1120","userName":"A.one","userSign":"","message":"我觉得这个想法 比起给手残去生成头像  <br>给职业画师做助手性质的软件会更有商业价值和生产性<br><br>如果可以用某个画师大量作品为基础素材分析 生成一套这个画师画风的加工流程<br>然后他自己画一个草稿之后的部分都可以自动完成的话 确实会很实用  <br>就算不能完全模仿 最后再自己修正一下 也已经省掉很多时间 非常实用了<br><br>站在画师的角度来说 画完线稿草稿 想好光影 （有些“画师”每张图光影都是一样的）<br>之后基本都是重复的无脑单纯作业 我都可以一边看着动画一边完成<br><br>顺便 这个软件能分图层吗？  画师交稿都是要给分层PSD的  否则收稿的AD那边没法修改","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/04/97/49777.jpg","floor":"#13-1","id":"1430976","time":"2019-3-28 12:43","userId":"bgmouse","userName":"MousHu","userSign":"","message":"可以去看看阿里的 鹿班 那边的相关的一些报导评价什么的 ... <br>同样也许能一定程度地解答#12-2的问题 ~"},{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#13-2","id":"1431139","time":"2019-3-29 10:20","userId":"197870","userName":"尤鱼哥","userSign":"","message":"正文里更新了一下说明你可以看下。<br>目前自动上色是比较成熟的，但是别的方向都……"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/26/63/266388.jpg","floor":"#14","id":"1431085","time":"2019-3-28 21:17","userId":"266388","userName":"恋花绽放樱飞时","userSign":"(www~)","message":"mark","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/27/51/275103.jpg","floor":"#15","id":"1431091","time":"2019-3-28 21:32","userId":"whwq2012","userName":"whwq2012","userSign":"","message":"学渣默默地问一句，南大是哪个，南开，南京，南昌？<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\">","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/30/18/301818.jpg","floor":"#15-1","id":"1431099","time":"2019-3-28 21:53","userId":"llllink","userName":"yo-u-zazazai✨","userSign":"","message":"南京大学啦，楼主github主页有写"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/31/65/316509.jpg","floor":"#16","id":"1431624","time":"2019-3-31 06:04","userId":"316509","userName":"Rivers","userSign":"(Don't feel. Think.)","message":"图都崩了啊<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\">","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/31/34/313469.jpg","floor":"#17","id":"1431652","time":"2019-3-31 12:01","userId":"313469","userName":"Cedar","userSign":"(｡´-д-)","message":"有什么自动上色软件是已经商用的了?<br>效果超越以往的自动上色为什么还不能商用呢..","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#17-1","id":"1432974","time":"2019-4-5 09:20","userId":"197870","userName":"尤鱼哥","userSign":"","message":"自动上色软件搜一下一大堆……这个和自动上色colorize不是同领域，自动上色是需要画师画出优秀线稿的。<br>而PI-REC只需要你提供非常稀疏的edge和color domain，它会自己生成出很多的细节部分，可以说随便涂几笔就行了。"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/25/55/255501.jpg","floor":"#18","id":"1431814","time":"2019-3-31 20:38","userId":"kakinuma","userName":"事实是柿子 - ⭐️VIP3","userSign":"(xD)","message":"你是一作，我先跪下了<img src=\"/img/smiles/tv/15.gif\" smileid=\"54\" alt=\"(bgm38)\">","sub":[]},{"avatar":"//lain.bgm.tv/pic/user/m/000/44/85/448502.jpg","floor":"#19","id":"1433705","time":"2019-4-7 23:28","userId":"448502","userName":"浅海","userSign":"","message":"悉数表达的算法对硬件要求还是挺高的","sub":[{"avatar":"//lain.bgm.tv/pic/user/m/000/44/85/448502.jpg","floor":"#19-1","id":"1433706","time":"2019-4-7 23:29","userId":"448502","userName":"浅海","userSign":"","message":"稀疏"},{"avatar":"//lain.bgm.tv/pic/user/m/000/19/78/197870.jpg","floor":"#19-2","id":"1434606","time":"2019-4-12 09:08","userId":"197870","userName":"尤鱼哥","userSign":"","message":"<div class=\"quote\"><q><span style=\"font-weight:bold;\">浅海</span> 说: 稀疏</q></div>论文里的稀疏sparse input仅仅指的是输入信息少量的意思，并不是说矩阵稀疏啦~~~"}]},{"avatar":"//lain.bgm.tv/pic/user/m/000/44/12/441202.jpg","floor":"#20","id":"1435289","time":"2019-4-15 21:37","userId":"441202","userName":"战王","userSign":"(15年宅史，战无不胜)","message":"等技术再成熟点就好了","sub":[]}]